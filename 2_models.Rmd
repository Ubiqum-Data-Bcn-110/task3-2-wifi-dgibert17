---
title: "2_Models"
author: "David Gibert Bosque"
date: "December 12, 2018"
output: html_document
---
```{r include=FALSE}
rm(list = ls())
```

```{r include=FALSE}
### LIBRARIES ###
library(dplyr)
library(Metrics)
library(rpart)
library(doParallel)
library(rpart.plot)
library(fastDummies)
library(ggplot2)
library(elasticnet)
library(lars)
library(caret)
library(AppliedPredictiveModeling)
library(e1071)
library(pls)
library(plotly)
```

```{r include=FALSE}
## LOADING DATA
setwd("C:/Users/David/Google Drive/Github/task3-2-wifi-dgibert17")

load(file = "training.Rdata")
load(file = "validation.Rdata")

# cl <- makeCluster(3)
# doParallel:::registerDoParallel(cl)
```

## Cheking structure of data
```{r}
str(df.train[,313:322])
```














#### OTHER STUFF
## Stop cluster
```{r}
stopCluster(cl)
```








## Dividimos los datos por edificios para que haya menos interferencia de WAPs de otros edificios. Detectaremos que WAPs no son registrados en cada edificio y los quitaremos.
```{r}
df.trainB0 = df.train %>%
  filter(BUILDINGID == 0)

df.trainB1 = df.train %>%
  filter(BUILDINGID == 1)

df.trainB2 = df.train %>%
  filter(BUILDINGID == 2)


B0.vec = c()
B1.vec = c()
B2.vec = c()

for (i in 1:last(grep(pattern = "WAP", names(df.trainB0)))){
  if (sum(df.trainB0[,i]) == 100*nrow(df.trainB0)){
    B0.vec = c(B0.vec, i)
    # print(i)
  }
}

for (i in 1:last(grep(pattern = "WAP", names(df.trainB1)))){
  if (sum(df.trainB1[,i]) == 100*nrow(df.trainB1)){
    B1.vec = c(B1.vec, i)
    # print(i)
  }
}

for (i in 1:last(grep(pattern = "WAP", names(df.trainB2)))){
  if (sum(df.trainB2[,i]) == 100*nrow(df.trainB2)){
    B2.vec = c(B2.vec, i)
    # print(i)
  }
}


df.trainB0 = df.trainB0[,-B0.vec]
df.trainB1 = df.trainB1[,-B1.vec]
df.trainB2 = df.trainB2[,-B2.vec]
```
