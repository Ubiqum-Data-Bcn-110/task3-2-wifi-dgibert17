---
title: "Predicting FLOOR on building 1"
author: "David Gibert Bosque"
date: "December 18, 2018"
output: html_document
---
```{r include=FALSE}
rm(list = ls())
```

#### CARGA DE LIBRERIAS Y DATOS
```{r include=FALSE}
library(dplyr)
library(class)
library(Metrics)
library(caret)
library(randomForest)
library(e1071)

### LOADING DATA ###
setwd("C:/Users/David/Google Drive/Github/task3-2-wifi-dgibert17")

load(file = "training.Rdata")
load(file = "validation.Rdata")
```

#### CREAMOS DF DE TRAINING Y VALIDATION PARA BUILDING 0
```{r}
df.train.B0 = df.train %>%
  filter(BUILDINGID == 1)

df.val.B0 = df.val %>%
  filter(BUILDINGID == 1)
```

#### VOLVEMOS A COMPROBAR QUE WAPS DEL TRAINING Y DEL VALIDATION NO TIENEN REGISTROS O CUALES TIENEN SOLO 1 REGISTRO, YA QUE AL DIVIDIR EL DF EN BUILDINGS, PODRIA HABER MUCHOS WAPS QUE NO SEAN DETECTADOS.
```{r}
WAPnotDetected.val = as.character()
WAPnotDetected.tr = as.character()

# VALIDATION DF

for (i in 1:which(names(df.val.B0)=="WAP508")){
  if (sum(df.val.B0[i]) == 100*nrow(df.val.B0)){
    #cat("El", names(df.val[i]), "no ha sido detectado por ningun dispositivo en el validation\n")
    WAPnotDetected.val = c(WAPnotDetected.val, names(df.val.B0[i]))
  }
}

# TRAINING DF

for (i in 1:which(names(df.train.B0)=="WAP508")){
  if (sum(df.train.B0[i]) == 100*nrow(df.train.B0)){
    #cat("El", names(df.train[i]), "no ha sido detectado por ningun dispositivo en el training\n")
    WAPnotDetected.tr = c(WAPnotDetected.tr, names(df.train.B0[i]))
  }
}
```

## Quitamos de los DFs los WAPs que no son detectados por almenos un dispositivo.
```{r}
WAPnotDetected.val
which(names(df.val.B0) %in% WAPnotDetected.val) #Estos son los indices de los atributos que no son detectados en el validation set, por lo que quitaremos estos atributos del validation set.

df.val.B0 = df.val.B0[, -which(names(df.val.B0) %in% WAPnotDetected.val)]
df.train.B0 = df.train.B0[, -which(names(df.train.B0) %in% WAPnotDetected.tr)]
```

## Buscamos cuales son los atributos que comparten ambos DFs. El intersect. Asi, despues podremos coger los indices de los atributos del intersect y seleccionarlos para cada uno de los dos DFs, por lo que ambos quedaran con la misma info.
```{r}
tr.in.val.idxs = which(names(df.train.B0) %in% names(df.val.B0))
df.train.B0 = df.train.B0[, tr.in.val.idxs]

val.in.tr.idxs = which(names(df.val.B0) %in% names(df.train.B0))
df.val.B0 = df.val.B0[, val.in.tr.idxs]

sum(names(df.train.B0) == names(df.val.B0))

# intersect(x = names(df.train), y = names(df.val))
```

#### ESTRUCTURA DE LOS DATOS
```{r}
df.train.B0$FLOOR = factor(df.train.B0$FLOOR)
df.train.B0$BUILDINGID = factor(df.train.B0$BUILDINGID)

df.val.B0$FLOOR = factor(df.val.B0$FLOOR)
df.val.B0$BUILDINGID = factor(df.val.B0$BUILDINGID)
```

#### CREACION DE PARTICION DE DATOS PARA FLOOR BUILDING 0
```{r}
floor.vec = createDataPartition(y = df.train.B0$FLOOR, times = 5, p = 0.1)

# Training data
floor.tr = df.train.B0[, c(1:last(grep(pattern = "WAP", names(df.train.B0))), which(names(df.train.B0) == "FLOOR"))]
floor.tr$FLOOR = factor(floor.tr$FLOOR)

#Proporcion de datos en TRAIN y SAMPLE
prop.table(table(df.train.B0$FLOOR))
prop.table(table(floor.tr$FLOOR))
```

#### PREDICCION DE FLOOR - KNN
```{r warning=FALSE}
knn.fit.floor = knn(train = floor.tr[,1:146], test = df.val.B0[,c(1:146)], cl = floor.tr[,147], k = 5)
confusionMatrix(data = factor(knn.fit.floor), reference = df.val.B0$FLOOR)

#Cuantos dispositivos se han clasificado mal por cada edificio.
abs(table(knn.fit.floor) - table(df.val.B0$FLOOR))
```

#### PREDICCION DE FLOOR - SVM (Linear & Radial)
```{r warning=FALSE}
svm.fit.floor <- svm(formula = FLOOR ~ ., data = floor.tr)
svm.pred.floor <- predict(svm.fit.floor, newdata = df.val.B0[,c(1:146)])

confusionMatrix(data = svm.pred.floor, reference = df.val.B0$FLOOR)

# #Cuantos dispositivos se han clasificado mal por cada edificio.
abs(table(svm.pred.floor) - table(df.val.B0$FLOOR))
```

#### PREDICCION DE FLOOR - RF
```{r}
# bestmtry = tuneRF(x = floor.tr[,1:146], y = floor.tr$FLOOR, ntreeTry = 400, plot = T,stepFactor = 1.5, improve = 1e-5)

rf.fit.floor = randomForest(x = floor.tr[,1:146], y = floor.tr$FLOOR, ntree = 400, mtry = 18)
rf.pred.floor = predict(rf.fit.floor, df.val.B0)
confusionMatrix(data = factor(rf.pred.floor), reference = df.val.B0$FLOOR)

#Cuantos dispositivos se han clasificado mal por cada Planta
abs(table(rf.pred.floor) - table(df.val.B0$FLOOR))
```

#### CAMBIAMOS VALORES DE FLOOR POR LOS PREDICHOS
```{r}
df.val.B0$FLOOR = rf.pred.floor
str(df.val.B0$FLOOR)
```


#### CREACION DE DF TRAINING Y VALIDATION CON FLOOR DUMMIFIED PARA PREDECIR LONGITUDE EN BUILDING 0
```{r}
pacman::p_load(fastDummies)

df.val.B0.dumm = dummy_cols(.data = df.val.B0, select_columns = "FLOOR", remove_first_dummy = FALSE)
df.val.B0.dumm = select(.data = df.val.B0.dumm, -FLOOR)

df.train.B0.dumm = dummy_cols(.data = df.train.B0, select_columns = "FLOOR", remove_first_dummy = FALSE)
df.train.B0.dumm = select(.data = df.train.B0.dumm, -FLOOR)
```

#### PREDICCION DE LATITUDE - SVM
```{r warning=FALSE}
svm.fit.lat <- svm(formula = LATITUDE ~ ., data = df.train.B0.dumm[,c(1:146, 148, 156:159)])
svm.pred.lat <- predict(svm.fit.lat, newdata = df.val.B0.dumm[,c(1:146, 156:159)])

rmse(actual = df.val.B0.dumm$LATITUDE, predicted = svm.pred.lat)
mae(actual = df.val.B0.dumm$LATITUDE, predicted = svm.pred.lat)
```

#### PREDICCION DE LATITUDE - LINEAR MODEL
```{r warning=FALSE}
lm.fit.lat <- lm(formula = LATITUDE ~ ., data = df.train.B0.dumm[,c(1:146, 148, 156:159)])
lm.pred.lat <- predict(lm.fit.lat, newdata = df.val.B0.dumm[,c(1:146, 156:159)])

rmse(actual = df.val.B0.dumm$LATITUDE, predicted = lm.pred.lat)
mae(actual = df.val.B0.dumm$LATITUDE, predicted = lm.pred.lat)
```

#### PREDICCION DE LATITUDE - RF
```{r}
# bestmtry = tuneRF(x = df.train.B0.dumm[,c(1:146, 156:159)], y = df.train.B0.dumm$LATITUDE, ntreeTry = 400, plot = T,stepFactor = 1.5, improve = 1e-5)

rf.fit.lat = randomForest(LATITUDE ~., df.train.B0.dumm[,c(1:146, 148, 156:159)], ntree = 400, mtry = 34)

rf.pred.lat = predict(rf.fit.lat, df.val.B0.dumm[,c(1:146, 156:159)])

rmse(actual = df.val.B0.dumm$LATITUDE, predicted = rf.pred.lat)
mae(actual = df.val.B0.dumm$LATITUDE, predicted = rf.pred.lat)
```


#### PREDICCION DE LATITUDE - KNN
```{r warning=FALSE}
pacman::p_load(FNN)

knn.fit.lat = knn.reg(train = df.train.B0.dumm[,c(1:146, 156:159)], test = df.val.B0.dumm[,c(1:146, 156:159)],
                       y = df.train.B0.dumm[, 148], k = 5,
                       algorithm = c("kd_tree", "cover_tree", "brute"))

rmse(actual = df.val.B0.dumm$LATITUDE, predicted = knn.fit.lat$pred)
mae(actual = df.val.B0.dumm$LATITUDE, predicted = knn.fit.lat$pred)
```

#### CAMBIAMOS VALORES DE LATITUDE POR LOS PREDICHOS
```{r}
df.val.B0.dumm$LATITUDE = rf.pred.lat
```


#### PREDICCION DE LONGITUDE USANDO ATRIBUTO LATITUDE TAMBIEN
#### PREDICCION DE LONGITUDE - SVM
```{r warning=FALSE}
svm.fit.long <- svm(formula = LONGITUDE ~ ., data = df.train.B0.dumm[,c(1:146, 147, 148, 156:159)])
svm.pred.long <- predict(svm.fit.long, newdata = df.val.B0.dumm[,c(1:146, 148, 156:159)])

rmse(actual = df.val.B0.dumm$LONGITUDE, predicted = svm.pred.long)
mae(actual = df.val.B0.dumm$LONGITUDE, predicted = svm.pred.long)
```

#### PREDICCION DE LONGITUDE - LINEAR MODEL
```{r warning=FALSE}
lm.fit.long <- lm(formula = LONGITUDE ~ ., data = df.train.B0.dumm[,c(1:146, 147, 148, 156:159)])
lm.pred.long <- predict(lm.fit.long, newdata = df.val.B0.dumm[,c(1:146, 148, 156:159)])

rmse(actual = df.val.B0.dumm$LONGITUDE, predicted = lm.pred.long)
mae(actual = df.val.B0.dumm$LONGITUDE, predicted = lm.pred.long)
```

#### PREDICCION DE LONGITUDE - RF
```{r}
# bestmtry = tuneRF(x = df.train.B0.dumm[,c(1:146, 148, 156:159)], y = df.train.B0.dumm$LONGITUDE, ntreeTry = 400, plot = T,stepFactor = 1.5, improve = 1e-5)

rf.fit.long = randomForest(LONGITUDE ~., df.train.B0.dumm[,c(1:146, 147, 148, 156:159)], ntree = 400, mtry = 50)

rf.pred.long = predict(rf.fit.long, df.val.B0.dumm[,c(1:146, 148, 156:159)])

rmse(actual = df.val.B0.dumm$LONGITUDE, predicted = rf.pred.long)
mae(actual = df.val.B0.dumm$LONGITUDE, predicted = rf.pred.long)
```

#### PREDICCION DE LONGITUDE - KNN
```{r warning=FALSE}
pacman::p_load(FNN)

knn.fit.long = knn.reg(train = df.train.B0.dumm[,c(1:146, 148, 156:159)], test = df.val.B0.dumm[,c(1:146, 148, 156:159)],
                       y = df.train.B0.dumm[,147], k = 5,
                       algorithm = c("kd_tree", "cover_tree", "brute"))

rmse(actual = df.val.B0.dumm$LONGITUDE, predicted = knn.fit.long$pred)
mae(actual = df.val.B0.dumm$LONGITUDE, predicted = knn.fit.long$pred)
```


#### CAMBIAMOS VALORES DE LONGITUDE POR LOS PREDICHOS
```{r}
# df.val.B0.dumm$LONGITUDE = rf.pred.long
```

#### ANALISIS DEL ERROR DE PREDICCION
PLOTEAR EN 3D VALIDATION Y TAL...