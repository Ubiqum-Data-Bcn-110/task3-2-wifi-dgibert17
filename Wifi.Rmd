---
title: "Wifi location"
author: "David Gibert Bosque"
date: "December 3, 2018"
output: html_document
---
```{r include=FALSE}
rm(list = ls())
```

```{r include=FALSE}
### LIBRARIES ###
library(dplyr)
library(Metrics)
library(rpart)
library(rpart.plot)
library(fastDummies)
library(ggplot2)
library(elasticnet)
library(lars)
library(caret)
library(AppliedPredictiveModeling)
library(e1071)
library(pls)
library(plotly)
```

```{r}
### LOADING DATA ###
setwd("C:/Users/David/Google Drive/Github/task3-2-wifi-dgibert17")

df.train = read.csv("training.csv")
df.val = read.csv("validation.csv")

sum(names(df.train) == names(df.val))
```
*Ambos DF tienen los mismos atributos, aunque en el validation no hay registros para SPACEID, RELATIVEPOSITION ni USERID.*

## Creamos DF con valores reales de VALIDATION y igualamos a 0 los valores correspondientes en el DF de VALIDATION original, para hacerlo de la manera mas real posible. Ademas, despues podremos comparar los errores de prediccion.
```{r}
real.values = df.val[,521:529]
df.val[,521:529] = 0
summary(df.val[,521:529]) #Nos aseguramos que los atributos son = 0
```



the validation fingerprints were
taken 3 months later than the training ones, and some
WAPs disappeared and new ones were introduced.

From the 520 detected WAPs in the UJIIndoorLoc
database, 312 of them were detected in training and
validation phases. 153 WAPs were only detected in
the training phase, and 55 new WAPs appeared in the
validation phase




Como se quitaron WAPs, en el validation test habra WAPs cuyos valores sean todo 100, porque al no estar, obviamente no podran ser registrados por un dispositivo.

Por tanto, primero quitaremos los WAPs del validation y del training que sean inutiles, mas adelante igualaremos el DF de training con los mismos atributos del validation.
```{r}
WAPnotDetected.val = as.character()

for (i in 1:which(names(df.val)=="WAP520")){
  if (sum(df.val[i]) == 100*nrow(df.val)){
    #cat("El", names(df.val[i]), "no ha sido detectado por ningun dispositivo en el validation\n")
    WAPnotDetected.val = c(WAPnotDetected.val, names(df.val[i]))
  }
}

WAPnotDetected.tr = as.character()

for (i in 1:which(names(df.train)=="WAP520")){
  if (sum(df.train[i]) == 100*nrow(df.train)){
    #cat("El", names(df.train[i]), "no ha sido detectado por ningun dispositivo en el training\n")
    WAPnotDetected.tr = c(WAPnotDetected.tr, names(df.train[i]))
  }
}

# df.WAPnotDetected.tr = df.train[, c(WAPnotDetected.tr, names(df.train[521:529]))]

# cat("El", round(length(WAPnotDetected.val)/520*100),"% de los WAPs no han sido detectados por ningun dispositivo en el training. La universidad esta perdiendo dinero con estos hardware. (Hay que comprobar si ocurre lo mismo para el test).")
```

## Visualizamos cuales son los WAPs del validation y training set que no son detectados por almenos un dispositivo y los quitamos de los DFs.
```{r}
WAPnotDetected.val
which(names(df.val) %in% WAPnotDetected.val) #Estos son los indices de los atributos que no son detectados en el validation set, por lo que quitaremos estos atributos del validation set.

df.val = df.val[, -which(names(df.val) %in% WAPnotDetected.val)]
df.train = df.train[, -which(names(df.train) %in% WAPnotDetected.tr)]
```

## Buscamos cuales son los atributos que comparten ambos DFs. El intersect. Asi, despues podremos coger los indices de los atributos del intersect y seleccionarlos para cada uno de los dos DFs, por lo que ambos quedaran con la misma info.
```{r}
tr.in.val.idxs = which(names(df.train) %in% names(df.val))
df.train = df.train[, tr.in.val.idxs]

val.in.tr.idxs = which(names(df.val) %in% names(df.train))
df.val = df.val[, val.in.tr.idxs]

sum(names(df.train) == names(df.val))

# intersect(x = names(df.train), y = names(df.val))
```

## Ahora vamos a buscar si hay capturas en TRAINING que no han sido detectadas por ningun WAP o si han sido detectadas unicamente por 1 WAP, las cuales quitaremos del DF y las estudiaremos para ver si tienen algo en comun.
```{r}
DEVICEnotDetected.tr = c()
DEVICEdetected1WAP.tr = c()

for (i in 1:nrow(df.train)){
  if (sum(df.train[i, 1:last(grep(pattern = "WAP", names(df.train)))]) == 100*last(grep(pattern = "WAP", names(df.train)))){
    #print(rownames(df.train[i,]))
    DEVICEnotDetected.tr = c(DEVICEnotDetected.tr, as.numeric(rownames(df.train[i,])))
  } else if (sum(df.train[i, 1:last(grep(pattern = "WAP", names(df.train)))] != 100) == 1){
    #print(rownames(df.train[i,]))
    DEVICEdetected1WAP.tr = c(DEVICEdetected1WAP.tr, as.numeric(rownames(df.train[i,])))
  }
}

# names(df.train[first(grep("[^WAP0-9]", names(df.train)))])

df.DEVICESnotDetected.tr = df.train[DEVICEnotDetected.tr, 313:length(names(df.train))]
df.DEVICEdetected1WAP.tr = df.train[DEVICEdetected1WAP.tr, 313:length(names(df.train))]

DEVICESrm.tr = sort(c(DEVICEnotDetected.tr, DEVICEdetected1WAP.tr))

df.train = df.train[-DEVICESrm.tr, ]
```
*Ahora el DF TRAINING solo contiene rows con capturas (dispositivos) que han detectado como minimo 2 WAPs.*

## Ahora vamos a buscar si hay capturas en VALIDATION que no han sido detectadas por ningun WAP o si han sido detectadas unicamente por 1 WAP, las cuales podremos quitar del DF y estudiarlas en un DF diferente, para ver si tienen algo en comun.
```{r}
DEVICEnotDetected.val = c()
DEVICEdetected1WAP.val = c()

for (i in 1:nrow(df.val)){
  if (sum(df.val[i, 1:last(grep(pattern = "WAP", names(df.val)))]) == 100*last(grep(pattern = "WAP", names(df.val)))){
    #print(rownames(df.val[i,]))
    DEVICEnotDetected.val = c(DEVICEnotDetected.val, as.numeric(rownames(df.val[i,])))
  } else if (sum(df.val[i, 1:last(grep(pattern = "WAP", names(df.val)))] != 100) == 1){
    #print(rownames(df.val[i,]))
    DEVICEdetected1WAP.val = c(DEVICEdetected1WAP.val, as.numeric(rownames(df.val[i,])))
  }
}

DEVICEnotDetected.val
DEVICEdetected1WAP.val

df.val = df.val[-DEVICEdetected1WAP.val, ]
```
*No hay ningun dispositivo en el VALIDATION que no haya sido detectado por ningun WAP (obviamente, ya que si no es detectado por WAPs no aparecera en esta base de datos). Todos han sido detectados por almenos 1 WAP. Ademas, solo hay un dispositivo que haya sido detectado por unicamente 1 WAP, el cual tambien quitamos.*



## Buscamos si en TRAINING y VALIDATION hay capturas y WAPs que tengan algun valor entre 0 y -30.
```{r}
# BUSCAMOS EN TRAINING

cptr30 = c()
WAPs30 = c()

for (i in 1:nrow(df.train[,1:312])){
  for (j in 1:ncol(df.train[,1:312])){
    if (df.train[i,j] <= 0 & df.train[i,j] >= -30){
      cptr30 = c(cptr30,i)
      WAPs30 = c(WAPs30,j)
    }
  }
}

cptr30 = unique(as.vector(cptr30))
WAPs30 = unique(as.vector(WAPs30))

df.cptr30 = df.train[cptr30,]
df.WAPs30 = df.train[,WAPs30]

############################
# HACER LOOP PARA CONTAR LA CANTIDAD DE VALORES ENTRE 0 Y -30 POR CADA WAP, ESTO PUEDE INDICARNOS WAPS QUE NO FUNCIONAN BIEN.

# COMPROBAR SI LAS CAPTURAS QUE TIENEN RSSI ENTRE 0 Y -30 ES POR EL PHONEID O SI POR EJEMPLO ES POR LA ZONA DONDE ESTA EL DISPOSITIVO (ESTO ES MUY PROBABLE YA QUE HABIA UN USUARIO QUE HABIA HECHO MUCHAS CAPTURAS EN LA MISMA ZONA (LATITUD Y LONGITUD) Y TODAS TENIAN VALORES RAROS DE ESTOS.)

# COMPARAR LOS WAPS Y CAPTURAS DEL VALIDATION CON EL PASO ANTERIOR, PARA ASEGURAR QUE LA ZONA TIENE MALA COBERTURA O QUE ERA CUESTION DEL USUARIO...

# CONFUSION MATRIX PARA KNN

# PLOTEAR LOCALIZACIONES DEL SAMPLE (IGNACIO DICE QUE LE ECHE UN VISTAZO)
############################


# BUSCAMOS EN VALIDATION

```





## Dividiremos los datos de training por edificio, para visualizar la forma de los edificios a partir de la localizacion (latitud y longitud) de las capturas. Tambien creamos los edificios para el validation, de momento por razones de visualizacion. Mas adelante ya veremos para que mas. Si que tendra sentido visualizar la distribucion del validation sobre el training por edificio (incluso por planta) despues de hacer la prediccion de edificio y planta, para ver la distancia entre el valor real y el predicho de una manera visual.

#### Podria tener sentido: Como un dispositivo detecta de media unos 17 WAPs, tiene sentido agrupar por edificio la informacion, ya que asi podremos eliminar muchos de los WAPs, ya que no tiene sentido tener en info de WAPs de un edificio diferente al que se esta tomando la captura. Incluso podriamos filtrar por plantas contiguas, esto lo hare mas adelante.
```{r}
### CREATING TRAIN BUILDINGS - LOOP ###

# df.trainB0 = data.frame(matrix(nrow = 0, ncol = length(names(df.train))))
# df.trainB1 = data.frame(matrix(nrow = 0, ncol = length(names(df.train))))
# df.trainB2 = data.frame(matrix(nrow = 0, ncol = length(names(df.train))))
# 
# colnames(df.trainB0) = names(df.train)
# colnames(df.trainB1) = names(df.train)
# colnames(df.trainB2) = names(df.train)
# 
# 
# for (i in 1:nrow(df.train)){
#   if (df.train[i, "BUILDINGID"] == 0){
#     df.trainB0 = rbind(df.trainB0, df.train[i,])
#   } else if (df.train[i, "BUILDINGID"] == 1) {
#     df.trainB1 = rbind(df.trainB1, df.train[i,])
#   } else {
#     df.trainB2 = rbind(df.trainB2, df.train[i,])
#   }
# }


### CREATING TRAIN BUILDINGS - PIPES ###

df.trainB0 = df.train %>%
  filter(BUILDINGID == 0)

df.trainB1 = df.train %>%
  filter(BUILDINGID == 1)

df.trainB2 = df.train %>%
  filter(BUILDINGID == 2)
```

## Obervamos la distribucion de las capturas del training que crean la forma de los edificios del campus.
```{r}
a <- list(
title = "",
zeroline = FALSE,
showline = FALSE,
showticklabels = FALSE,
showgrid = FALSE
)

# All buildings, 2d
plot_ly(data = df.train, x = ~LONGITUDE, y = ~LATITUDE, color = ~factor(BUILDINGID)) %>%
  layout(xaxis = a,
         yaxis = a)

# All buildings, 3d
plot_ly(data = df.train, x = ~LONGITUDE, y = ~LATITUDE, z = ~factor(FLOOR),
        color = ~factor(BUILDINGID)) %>%
  layout(xaxis = a,
         yaxis = a)

# Building 0, 3d
plot_ly(data = df.trainB0, x = ~LONGITUDE, y = ~LATITUDE, z = ~factor(FLOOR),
        color = ~factor(FLOOR)) %>%
  layout(title = "Building 0",
         xaxis = a,
         yaxis = a
         )

# Building 1, 3d
plot_ly(data = df.trainB1, x = ~LONGITUDE, y = ~LATITUDE, z = ~factor(FLOOR),
        color = ~factor(FLOOR)) %>%
  layout(title = "Building 1",
         xaxis = a,
         yaxis = a
         )

# Building 2, 3d
plot_ly(data = df.trainB2, x = ~LONGITUDE, y = ~LATITUDE, z = ~factor(FLOOR),
        color = ~factor(FLOOR)) %>%
  layout(title = "Building 2",
         xaxis = a,
         yaxis = a
         )
```

## KNN para BUILDING a partir de una muestra pequeña.
```{r warning=FALSE}
building.vec = createDataPartition(y = df.train$BUILDINGID, times = 2, p = 0.05) #Particion proporcional

df.BUILDINGID.tr = df.train[building.vec$Resample1, c(1:312,316)]
df.BUILDINGID.tr$BUILDINGID = factor(df.BUILDINGID.tr$BUILDINGID)
df.BUILDINGID.test = df.train[building.vec$Resample2, c(1:312)]

prop.table(table(df.BUILDINGID.tr$BUILDINGID)) #Prop.table para TRAINING
prop.table(table(df.train$BUILDINGID)) #Prop.table para SAMPLE

ctrl = trainControl(method = "repeatedcv",
                    number = 3,
                    repeats = 10)

knn.Fit = train(BUILDINGID~.,
                method = "knn",
                preProcess = c("center","scale"),
                trControl = ctrl,
                data = df.BUILDINGID.tr)
knn.Fit

knn.pred = predict(knn.Fit, df.BUILDINGID.test)
accuracy(actual = df.train[building.vec$Resample2, "BUILDINGID"], predicted = knn.pred)

#Cuantas observaciones hay por edificio predichas y cuantas hay en realidad.
table(knn.pred)
table(df.train[building.vec$Resample2, "BUILDINGID"])

#Cuantos dispositivos se han clasificado mal por cada edificio.
abs(table(knn.pred) - table(df.train[building.vec$Resample2, "BUILDINGID"]))
```

## PLS to predict LONGITUDE & LATITUDE because REGRESSION issue.
```{r}
# df.BUILDINGID.tr = df.train[,c(1:312,316)]
# df.BUILDINGID.val = df.val[,1:312]
# 
# pls.Fit = plsr(BUILDINGID~., data = df.BUILDINGID.tr, validation = "CV")
# pls.pred = predict(pls.Fit, df.BUILDINGID.val, ncomp = 1:4)
# 
# validationplot(pls.Fit, val.type="RMSEP")
# validationplot(pls.Fit, val.type="R2")
# 
# 
# pls.RMSEP = RMSEP(pls.Fit, estimate="CV")
# plot(pls.RMSEP, main="RMSEP PLS Solubility", xlab="components")
# min_comp = which.min(pls.RMSEP$val)
# points(min_comp, min(pls.RMSEP$val), pch=1, col="red", cex=1.5)
# min_comp
# 
# plot(pls.Fit, ncomp=4, asp=1, line=TRUE)
```












## Comprobamos que el WAP001 es detectado almenos en un edificio tanto en training como en validation sets. Esto podria ser util para intentar detectar que WAPs pertenecen a cada edificio y asi poder hacer modelos predictivos en funcion del edificio. Esto es factibe si y solo si un dispositivo es detectado por WAPs del mismo edificio, no por WAPs de diferentes edificios. Cuando haga esto, puedo estudiarlo y ver si, en caso de que esto ultimo se de, se podria manejar de alguna manera.
```{r}
table(df.trainB0$WAP001)
table(df.trainB1$WAP001)
table(df.trainB2$WAP001)
```
*Esto indica que podemos eliminar los datos del WAP001 del edificio 1 y 2. Sabemos que ese WAP pertenece al edificio 0 y no esta detectado por ningun dispositivo en otro edificio.*







